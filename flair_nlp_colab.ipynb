{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sF_9MAOKPyAY"
   },
   "source": [
    "Resume NER Part 4: Working with Flair NLP\n",
    "\n",
    "---\n",
    "\n",
    "In this part we will use flair NLP to train a model on our data and evaluate the results. Please make sure you have set up your Google account and uploaded your files to Google drive. This Notebook should run on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uXoVFeGlQdEu"
   },
   "source": [
    "Let's change the working directory to the Google drive where our training data is, and install flair nlp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXiOU9ihIHvX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/content/gdrive/My Drive/SAKI_2019/dataset\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4951,
     "status": "ok",
     "timestamp": 1559109520946,
     "user": {
      "displayName": "John Loutzenhiser",
      "photoUrl": "",
      "userId": "15304265471745504805"
     },
     "user_tz": -120
    },
    "id": "l8542ZPSnM_d",
    "outputId": "6b164dc7-fa69-401e-f35f-0b0a181f8c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.4.1)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.3)\n",
      "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.7)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
      "Requirement already satisfied: pytorch-pretrained-bert>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.6.2)\n",
      "Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
      "Requirement already satisfied: regex==2018.1.10 in /usr/local/lib/python3.6/dist-packages (from flair) (2018.1.10)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.5)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.1.0)\n",
      "Requirement already satisfied: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair) (0.2.12)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.3.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.16.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.5.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.154)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.1)\n",
      "Requirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.10.11)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.8.3)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (0.1.82)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.3->flair) (41.0.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert>=0.6.1->flair) (3.0.4)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.154 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.154)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.12.5)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.154->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n"
     ]
    }
   ],
   "source": [
    "# download flair library #\n",
    "! pip install flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOWwKlH8QwBU"
   },
   "source": [
    "In the next section, we will train a NER model with flair. This code is taken from the flair nlp tutorials section 7. \"Training a model\" \n",
    "https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jmj6vZ_AmD4c"
   },
   "outputs": [],
   "source": [
    "# imports \n",
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from typing import List\n",
    "\n",
    "# columns of \"gold standard\" ner annotations and text\n",
    "columns = {3: 'text', 1: 'ner'}\n",
    "\n",
    "# folder where training and test data are\n",
    "data_folder = '/content/gdrive/My Drive/SAKI_2019/dataset/flair'\n",
    "\n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 235720,
     "status": "ok",
     "timestamp": 1559112235927,
     "user": {
      "displayName": "John Loutzenhiser",
      "photoUrl": "",
      "userId": "15304265471745504805"
     },
     "user_tz": -120
    },
    "id": "Ghp5-JZTRYOb",
    "outputId": "0229b4fc-255a-41d3-947d-5db0687bc710"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 06:40:00,461 Reading data from /content/gdrive/My Drive/SAKI_2019/dataset/flair\n",
      "2019-05-29 06:40:00,465 Train: /content/gdrive/My Drive/SAKI_2019/dataset/flair/train_res_bilou.txt\n",
      "2019-05-29 06:40:00,468 Dev: None\n",
      "2019-05-29 06:40:00,471 Test: /content/gdrive/My Drive/SAKI_2019/dataset/flair/test_res_bilou.txt\n",
      "TaggedCorpus: 250339 train + 27816 dev + 123300 test sentences\n",
      "[b'<unk>', b'O', b'ner', b'\"B-Companies', b'\"L-Companies', b'B-Designation', b'L-Designation', b'B-Degree', b'I-Degree', b'L-Degree', b'\"I-Companies', b'U-Degree', b'U-Designation', b'-', b'I-Designation', b'\"U-Companies', b'<START>', b'<STOP>']\n"
     ]
    }
   ],
   "source": [
    "downsample = 1.0 # 1.0 is full data, try a much smaller number like 0.01 to test run the code\n",
    "# 1. get the corpus\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.load_column_corpus(data_folder, columns,\n",
    "                                                              train_file='train_res_bilou.txt',\n",
    "                                                              test_file='test_res_bilou.txt',\n",
    "                                                              dev_file=None).downsample(downsample)\n",
    "print(corpus)\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8821,
     "status": "ok",
     "timestamp": 1559112343925,
     "user": {
      "displayName": "John Loutzenhiser",
      "photoUrl": "",
      "userId": "15304265471745504805"
     },
     "user_tz": -120
    },
    "id": "o6H1IzUbR5iH",
    "outputId": "e2ae9e8e-1175-4265-d7db-f377cbc49649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 06:45:35,331 this function is deprecated, use smart_open.open instead\n",
      "2019-05-29 06:45:38,247 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-forward--h2048-l1-d0.05-lr30-0.25-20/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpxwei3ktf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034624/73034624 [00:01<00:00, 52411692.82B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 06:45:39,802 copying /tmp/tmpxwei3ktf to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 06:45:39,895 removing temp file /tmp/tmpxwei3ktf\n",
      "2019-05-29 06:45:40,252 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-backward--h2048-l1-d0.05-lr30-0.25-20/news-backward-0.4.1.pt not found in cache, downloading to /tmp/tmpti48vaf0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73034575/73034575 [00:02<00:00, 34685957.84B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 06:45:42,580 copying /tmp/tmpti48vaf0 to cache at /root/.flair/embeddings/news-backward-0.4.1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 06:45:42,700 removing temp file /tmp/tmpti48vaf0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. initialize embeddings. Experiment with different embedding types to see what gets the best results\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings,FlairEmbeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "    WordEmbeddings('glove'),\n",
    "    # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings (needs a LONG time to train :-)\n",
    "    FlairEmbeddings('news-forward'),\n",
    "    FlairEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2822
    },
    "colab_type": "code",
    "id": "xFMA2qsyTvHq",
    "outputId": "5171e852-4d60-4e94-abd1-e3645a896709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-29 06:47:44,438 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 06:47:44,444 Evaluation method: MICRO_F1_SCORE\n",
      "2019-05-29 06:47:44,460 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 06:47:44,928 epoch 1 - iter 0/7824 - loss 1.92333972\n",
      "2019-05-29 06:49:35,002 epoch 1 - iter 782/7824 - loss 0.19444647\n",
      "2019-05-29 06:51:25,299 epoch 1 - iter 1564/7824 - loss 0.18598820\n",
      "2019-05-29 06:53:17,041 epoch 1 - iter 2346/7824 - loss 0.18227333\n",
      "2019-05-29 06:55:06,784 epoch 1 - iter 3128/7824 - loss 0.17781647\n",
      "2019-05-29 06:56:55,693 epoch 1 - iter 3910/7824 - loss 0.17597449\n",
      "2019-05-29 06:58:44,580 epoch 1 - iter 4692/7824 - loss 0.17390317\n",
      "2019-05-29 07:00:35,751 epoch 1 - iter 5474/7824 - loss 0.17285590\n",
      "2019-05-29 07:02:27,766 epoch 1 - iter 6256/7824 - loss 0.17155321\n",
      "2019-05-29 07:04:19,223 epoch 1 - iter 7038/7824 - loss 0.17102515\n",
      "2019-05-29 07:06:11,540 epoch 1 - iter 7820/7824 - loss 0.17058596\n",
      "2019-05-29 07:06:12,638 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 07:06:12,642 EPOCH 1 done: loss 0.1706 - lr 0.1000 - bad epochs 0\n",
      "2019-05-29 07:07:49,750 DEV  : loss 0.15114701 - f-score 0.2139 - acc 0.1198\n",
      "2019-05-29 07:14:44,699 TEST : loss 0.13148454 - f-score 0.2176 - acc 0.1221\n",
      "2019-05-29 07:14:51,439 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 07:14:51,875 epoch 2 - iter 0/7824 - loss 0.04214245\n",
      "2019-05-29 07:15:56,990 epoch 2 - iter 782/7824 - loss 0.16243985\n",
      "2019-05-29 07:17:01,044 epoch 2 - iter 1564/7824 - loss 0.16569587\n",
      "2019-05-29 07:18:03,702 epoch 2 - iter 2346/7824 - loss 0.16563938\n",
      "2019-05-29 07:19:07,230 epoch 2 - iter 3128/7824 - loss 0.16546994\n",
      "2019-05-29 07:20:10,446 epoch 2 - iter 3910/7824 - loss 0.16538590\n",
      "2019-05-29 07:21:13,610 epoch 2 - iter 4692/7824 - loss 0.16381707\n",
      "2019-05-29 07:22:17,342 epoch 2 - iter 5474/7824 - loss 0.16284518\n",
      "2019-05-29 07:23:21,191 epoch 2 - iter 6256/7824 - loss 0.16215064\n",
      "2019-05-29 07:24:24,147 epoch 2 - iter 7038/7824 - loss 0.16249019\n",
      "2019-05-29 07:25:27,113 epoch 2 - iter 7820/7824 - loss 0.16223546\n",
      "2019-05-29 07:25:28,074 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 07:25:28,079 EPOCH 2 done: loss 0.1622 - lr 0.1000 - bad epochs 0\n",
      "2019-05-29 07:26:06,456 DEV  : loss 0.14756045 - f-score 0.3124 - acc 0.1851\n",
      "2019-05-29 07:28:56,450 TEST : loss 0.12805009 - f-score 0.3214 - acc 0.1915\n",
      "2019-05-29 07:29:03,068 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 07:29:03,563 epoch 3 - iter 0/7824 - loss 0.07504035\n",
      "2019-05-29 07:30:07,962 epoch 3 - iter 782/7824 - loss 0.15646145\n",
      "2019-05-29 07:31:11,636 epoch 3 - iter 1564/7824 - loss 0.15865102\n",
      "2019-05-29 07:32:14,367 epoch 3 - iter 2346/7824 - loss 0.15765719\n",
      "2019-05-29 07:33:17,107 epoch 3 - iter 3128/7824 - loss 0.15960736\n",
      "2019-05-29 07:34:20,474 epoch 3 - iter 3910/7824 - loss 0.16101051\n",
      "2019-05-29 07:35:24,156 epoch 3 - iter 4692/7824 - loss 0.16187505\n",
      "2019-05-29 07:36:27,509 epoch 3 - iter 5474/7824 - loss 0.16137101\n",
      "2019-05-29 07:37:30,682 epoch 3 - iter 6256/7824 - loss 0.16165024\n",
      "2019-05-29 07:38:34,211 epoch 3 - iter 7038/7824 - loss 0.16160238\n",
      "2019-05-29 07:39:37,504 epoch 3 - iter 7820/7824 - loss 0.16159062\n",
      "2019-05-29 07:39:38,434 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 07:39:38,438 EPOCH 3 done: loss 0.1616 - lr 0.1000 - bad epochs 0\n",
      "2019-05-29 07:40:17,540 DEV  : loss 0.15263946 - f-score 0.3399 - acc 0.2047\n",
      "2019-05-29 07:43:08,571 TEST : loss 0.13227631 - f-score 0.3271 - acc 0.1955\n",
      "2019-05-29 07:43:14,959 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 07:43:17,943 epoch 4 - iter 0/7824 - loss 0.25562543\n",
      "2019-05-29 07:44:23,285 epoch 4 - iter 782/7824 - loss 0.16776333\n",
      "2019-05-29 07:45:27,160 epoch 4 - iter 1564/7824 - loss 0.16404109\n",
      "2019-05-29 07:46:30,861 epoch 4 - iter 2346/7824 - loss 0.16417919\n",
      "2019-05-29 07:47:33,920 epoch 4 - iter 3128/7824 - loss 0.16321478\n",
      "2019-05-29 07:48:37,153 epoch 4 - iter 3910/7824 - loss 0.16273096\n",
      "2019-05-29 07:49:40,450 epoch 4 - iter 4692/7824 - loss 0.16166176\n",
      "2019-05-29 07:50:44,029 epoch 4 - iter 5474/7824 - loss 0.16107465\n",
      "2019-05-29 07:51:48,264 epoch 4 - iter 6256/7824 - loss 0.16131535\n",
      "2019-05-29 07:52:52,688 epoch 4 - iter 7038/7824 - loss 0.16045058\n",
      "2019-05-29 07:53:56,781 epoch 4 - iter 7820/7824 - loss 0.16000103\n",
      "2019-05-29 07:53:57,771 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 07:53:57,773 EPOCH 4 done: loss 0.1600 - lr 0.1000 - bad epochs 0\n",
      "2019-05-29 07:54:36,613 DEV  : loss 0.17088117 - f-score 0.1871 - acc 0.1032\n",
      "2019-05-29 07:57:28,551 TEST : loss 0.14878590 - f-score 0.2120 - acc 0.1186\n",
      "2019-05-29 07:57:35,066 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 07:57:35,547 epoch 5 - iter 0/7824 - loss 0.04924622\n",
      "2019-05-29 07:58:40,688 epoch 5 - iter 782/7824 - loss 0.15684902\n",
      "2019-05-29 07:59:45,812 epoch 5 - iter 1564/7824 - loss 0.15796107\n",
      "2019-05-29 08:00:50,889 epoch 5 - iter 2346/7824 - loss 0.15524229\n",
      "2019-05-29 08:01:55,825 epoch 5 - iter 3128/7824 - loss 0.15686212\n",
      "2019-05-29 08:03:01,223 epoch 5 - iter 3910/7824 - loss 0.15822395\n",
      "2019-05-29 08:04:06,568 epoch 5 - iter 4692/7824 - loss 0.15862427\n",
      "2019-05-29 08:05:11,047 epoch 5 - iter 5474/7824 - loss 0.15909630\n",
      "2019-05-29 08:06:14,930 epoch 5 - iter 6256/7824 - loss 0.15983722\n",
      "2019-05-29 08:07:19,412 epoch 5 - iter 7038/7824 - loss 0.16076979\n",
      "2019-05-29 08:08:24,419 epoch 5 - iter 7820/7824 - loss 0.16058466\n",
      "2019-05-29 08:08:25,402 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 08:08:25,404 EPOCH 5 done: loss 0.1606 - lr 0.1000 - bad epochs 0\n",
      "2019-05-29 08:09:05,421 DEV  : loss 0.14952748 - f-score 0.3095 - acc 0.1831\n",
      "2019-05-29 08:11:56,449 TEST : loss 0.13247426 - f-score 0.3154 - acc 0.1872\n",
      "2019-05-29 08:11:56,461 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 08:11:56,878 epoch 6 - iter 0/7824 - loss 0.01470995\n",
      "2019-05-29 08:13:00,123 epoch 6 - iter 782/7824 - loss 0.16025849\n",
      "2019-05-29 08:14:03,338 epoch 6 - iter 1564/7824 - loss 0.15592812\n",
      "2019-05-29 08:15:06,487 epoch 6 - iter 2346/7824 - loss 0.15833454\n",
      "2019-05-29 08:16:09,895 epoch 6 - iter 3128/7824 - loss 0.15821865\n",
      "2019-05-29 08:17:12,959 epoch 6 - iter 3910/7824 - loss 0.15762750\n",
      "2019-05-29 08:18:15,982 epoch 6 - iter 4692/7824 - loss 0.15926151\n",
      "2019-05-29 08:19:19,113 epoch 6 - iter 5474/7824 - loss 0.16107464\n",
      "2019-05-29 08:20:21,875 epoch 6 - iter 6256/7824 - loss 0.16083237\n",
      "2019-05-29 08:21:24,344 epoch 6 - iter 7038/7824 - loss 0.16113707\n",
      "2019-05-29 08:22:27,048 epoch 6 - iter 7820/7824 - loss 0.16058753\n",
      "2019-05-29 08:22:27,988 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 08:22:27,990 EPOCH 6 done: loss 0.1606 - lr 0.1000 - bad epochs 1\n",
      "2019-05-29 08:23:06,283 DEV  : loss 0.15542631 - f-score 0.2296 - acc 0.1297\n",
      "2019-05-29 08:25:56,094 TEST : loss 0.13418236 - f-score 0.2684 - acc 0.1550\n",
      "2019-05-29 08:25:56,106 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 08:25:56,575 epoch 7 - iter 0/7824 - loss 0.05445121\n",
      "2019-05-29 08:26:59,887 epoch 7 - iter 782/7824 - loss 0.15708067\n",
      "2019-05-29 08:28:02,874 epoch 7 - iter 1564/7824 - loss 0.15950242\n",
      "2019-05-29 08:29:05,591 epoch 7 - iter 2346/7824 - loss 0.16311086\n",
      "2019-05-29 08:30:08,413 epoch 7 - iter 3128/7824 - loss 0.15905079\n",
      "2019-05-29 08:31:11,480 epoch 7 - iter 3910/7824 - loss 0.15965784\n",
      "2019-05-29 08:32:14,533 epoch 7 - iter 4692/7824 - loss 0.16064975\n",
      "2019-05-29 08:33:17,734 epoch 7 - iter 5474/7824 - loss 0.16073414\n",
      "2019-05-29 08:34:21,899 epoch 7 - iter 6256/7824 - loss 0.16061562\n",
      "2019-05-29 08:35:26,809 epoch 7 - iter 7038/7824 - loss 0.16014444\n",
      "2019-05-29 08:36:30,612 epoch 7 - iter 7820/7824 - loss 0.16024564\n",
      "2019-05-29 08:36:31,546 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 08:36:31,551 EPOCH 7 done: loss 0.1602 - lr 0.1000 - bad epochs 2\n",
      "2019-05-29 08:37:10,295 DEV  : loss 0.16030464 - f-score 0.2343 - acc 0.1326\n",
      "2019-05-29 08:39:58,503 TEST : loss 0.14129154 - f-score 0.2410 - acc 0.1370\n",
      "2019-05-29 08:39:58,515 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 08:39:58,947 epoch 8 - iter 0/7824 - loss 0.44601130\n",
      "2019-05-29 08:41:01,812 epoch 8 - iter 782/7824 - loss 0.16823898\n",
      "2019-05-29 08:42:04,524 epoch 8 - iter 1564/7824 - loss 0.16315029\n",
      "2019-05-29 08:43:06,661 epoch 8 - iter 2346/7824 - loss 0.16270385\n",
      "2019-05-29 08:44:09,862 epoch 8 - iter 3128/7824 - loss 0.16209948\n",
      "2019-05-29 08:45:12,754 epoch 8 - iter 3910/7824 - loss 0.16291254\n",
      "2019-05-29 08:46:15,841 epoch 8 - iter 4692/7824 - loss 0.16168542\n",
      "2019-05-29 08:47:20,811 epoch 8 - iter 5474/7824 - loss 0.16136439\n",
      "2019-05-29 08:48:25,483 epoch 8 - iter 6256/7824 - loss 0.16066021\n",
      "2019-05-29 08:49:29,379 epoch 8 - iter 7038/7824 - loss 0.16065652\n",
      "2019-05-29 08:50:32,308 epoch 8 - iter 7820/7824 - loss 0.16120052\n",
      "2019-05-29 08:50:33,280 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 08:50:33,282 EPOCH 8 done: loss 0.1612 - lr 0.1000 - bad epochs 3\n",
      "2019-05-29 08:51:11,027 DEV  : loss 0.14842677 - f-score 0.2207 - acc 0.1240\n",
      "2019-05-29 08:53:58,563 TEST : loss 0.13003550 - f-score 0.2490 - acc 0.1422\n",
      "Epoch     7: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-05-29 08:53:58,576 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 08:53:59,062 epoch 9 - iter 0/7824 - loss 0.20096138\n",
      "2019-05-29 08:55:01,910 epoch 9 - iter 782/7824 - loss 0.15452933\n",
      "2019-05-29 08:56:04,536 epoch 9 - iter 1564/7824 - loss 0.15074025\n",
      "2019-05-29 08:57:07,042 epoch 9 - iter 2346/7824 - loss 0.15100096\n",
      "2019-05-29 08:58:09,242 epoch 9 - iter 3128/7824 - loss 0.15028506\n",
      "2019-05-29 08:59:11,652 epoch 9 - iter 3910/7824 - loss 0.15107855\n",
      "2019-05-29 09:00:14,053 epoch 9 - iter 4692/7824 - loss 0.15055839\n",
      "2019-05-29 09:01:17,121 epoch 9 - iter 5474/7824 - loss 0.15022738\n",
      "2019-05-29 09:02:19,297 epoch 9 - iter 6256/7824 - loss 0.15166013\n",
      "2019-05-29 09:03:21,822 epoch 9 - iter 7038/7824 - loss 0.15078598\n",
      "2019-05-29 09:04:24,618 epoch 9 - iter 7820/7824 - loss 0.15071279\n",
      "2019-05-29 09:04:25,581 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 09:04:25,583 EPOCH 9 done: loss 0.1507 - lr 0.0500 - bad epochs 0\n",
      "2019-05-29 09:05:03,778 DEV  : loss 0.14973716 - f-score 0.2989 - acc 0.1757\n",
      "2019-05-29 09:07:53,440 TEST : loss 0.13091907 - f-score 0.2942 - acc 0.1725\n",
      "2019-05-29 09:07:59,911 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 09:08:00,339 epoch 10 - iter 0/7824 - loss 0.03652756\n",
      "2019-05-29 09:09:04,054 epoch 10 - iter 782/7824 - loss 0.15205172\n",
      "2019-05-29 09:10:07,284 epoch 10 - iter 1564/7824 - loss 0.15029223\n",
      "2019-05-29 09:11:09,976 epoch 10 - iter 2346/7824 - loss 0.14907135\n",
      "2019-05-29 09:12:12,862 epoch 10 - iter 3128/7824 - loss 0.14998028\n",
      "2019-05-29 09:13:15,635 epoch 10 - iter 3910/7824 - loss 0.15041971\n",
      "2019-05-29 09:14:18,607 epoch 10 - iter 4692/7824 - loss 0.15009316\n",
      "2019-05-29 09:15:21,775 epoch 10 - iter 5474/7824 - loss 0.15006633\n",
      "2019-05-29 09:16:25,008 epoch 10 - iter 6256/7824 - loss 0.15028308\n",
      "2019-05-29 09:17:27,720 epoch 10 - iter 7038/7824 - loss 0.14990121\n",
      "2019-05-29 09:18:30,043 epoch 10 - iter 7820/7824 - loss 0.14937831\n",
      "2019-05-29 09:18:30,964 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 09:18:30,972 EPOCH 10 done: loss 0.1494 - lr 0.0500 - bad epochs 0\n",
      "2019-05-29 09:19:09,331 DEV  : loss 0.14000110 - f-score 0.2823 - acc 0.1644\n",
      "2019-05-29 09:21:58,419 TEST : loss 0.12276030 - f-score 0.2821 - acc 0.1642\n",
      "2019-05-29 09:22:05,154 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-29 09:22:05,633 epoch 11 - iter 0/7824 - loss 0.00714326\n",
      "2019-05-29 09:23:09,518 epoch 11 - iter 782/7824 - loss 0.15290185\n",
      "2019-05-29 09:24:12,458 epoch 11 - iter 1564/7824 - loss 0.15151157\n"
     ]
    }
   ],
   "source": [
    "# 6. initialize trainer\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "trainer: ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train('resources/taggers/resume-ner',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=150)\n",
    "\n",
    "# 8. plot training curves (optional)\n",
    "#from flair.visual.training_curves import Plotter\n",
    "#plotter = Plotter()\n",
    "#plotter.plot_training_curves('resources/taggers/example-ner/loss.tsv')\n",
    "#plotter.plot_weights('resources/taggers/example-ner/weights.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOtNSVB3Ok9H"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GPU_Flair_NER_34_percent.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
